
MySQL 的行锁是由各个引擎自己实现的，并不是所有的引擎都支持行锁，不支持行锁意味着并发控制只能使用表锁。MyISAM 不支持行锁，InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

# 1.两阶段锁

例1：

>假设字段 id 是表 t 的主键，事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。

![](./images/7/1.png)

两阶段锁协议：在 InnoDB 事务中，行锁是在需要的时候才加上的，但是要等到事务结束时才释放。因此，如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。

## 2.死锁和死锁检测

死锁：当并发系统中不同线程出现循环资源依赖，都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。

例2：

>事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。

![](./images/7/1.png)

当出现死锁以后，有两种策略：

（1）直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。

（2）发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。回滚的事务可以在业务代码进行重试，一般不会造成业务损失。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

innodb_lock_wait_timeout 的默认值是 50s，这个等待时间是无法接受的。如果把它调小，能够很快解决死锁，但是会对锁等待造成误伤。因此，正常情况下都是采用第二种策略，并且 innodb_deadlock_detect 的默认值本身就是 on，这也导致CPU 利用率很高。

那么如何解决热点行更新导致的性能问题呢？

（1）关闭死锁检测。可能会出现大量的超时，进而业务有损。

（2）控制并发度。修改 MySQL 源码，对于相同行的更新，在进入引擎之前排队。

# 3.问题

如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：

第一种，直接执行 delete from T limit 10000;

第二种，在一个连接中循环执行 20 次 delete from T limit 500;

第三种，在 20 个连接中同时执行 delete from T limit 500。

你会选择哪一种方法呢？为什么呢？

选择2。第1种，长事务；第三种，人为锁冲突。最好是先拿到行数据 id，然后进行删除。
